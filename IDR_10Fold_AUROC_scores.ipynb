{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score,\n",
    "                             recall_score, roc_curve,roc_auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_csv_files(file_path: str):\n",
    "    with open(file_path, newline=\"\") as file:\n",
    "        reader = csv.reader(file, delimiter=\"\\t\", lineterminator=\"\\n\")\n",
    "        arr = []\n",
    "        for x in reader:\n",
    "            t = ()\n",
    "            t = t + (x[0],) + (x[1],)\n",
    "            arr.append(t)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs_order_uniq(iteration, seed=30):\n",
    "    \n",
    "    filename_1 = \"./asymmetric_pairs/trainingpositive_idp_crossval\"+str(iteration)+\".csv\"\n",
    "    training_positive_pairs = read_csv_files(filename_1)\n",
    "\n",
    "    filename_2 = \"./asymmetric_pairs/testpositive_idp_crossval\"+str(iteration)+\".csv\"\n",
    "    test_positive_pairs = read_csv_files(filename_2)\n",
    "\n",
    "    filename_3 = \"./asymmetric_pairs/outbalanced_c2_16_negative_training_crossval\"+str(iteration)+\".csv\"\n",
    "    training_negative_pairs = read_csv_files(filename_3)\n",
    "\n",
    "    filename_4 = \"./asymmetric_pairs/testnegative_crossval\"+str(iteration)+\".csv\" \n",
    "    test_negative_pairs = read_csv_files(filename_4)\n",
    "\n",
    "    positive_pairs = training_positive_pairs + test_positive_pairs\n",
    "    negative_pairs = training_negative_pairs + test_negative_pairs\n",
    "\n",
    "    all_pairs = [\n",
    "        training_positive_pairs,\n",
    "        test_positive_pairs,\n",
    "        training_negative_pairs,\n",
    "        test_negative_pairs,\n",
    "    ]\n",
    "\n",
    "    return (positive_pairs, negative_pairs, all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "def preprocessing_features_orig(input_feature,operator,positive_pairs,negative_pairs):\n",
    "    \n",
    "    newdict=input_feature.to_dict(orient=\"index\")\n",
    "\n",
    "   \n",
    "    dfs=[]\n",
    "    for pairs in (positive_pairs,negative_pairs):\n",
    "        #print(pairs)\n",
    "       \n",
    "        if operator == 'abs_minus' :\n",
    "            features2={}\n",
    "            for keys in pairs:\n",
    "                test_dict1=newdict[keys[0]]\n",
    "                test_dict2=newdict[keys[1]]\n",
    "                #print(test_dict1)\n",
    "                #print(test_dict2)\n",
    "                res = {key: abs(test_dict2[key] - test_dict1.get(key, 0)) for key in test_dict2.keys()}  \n",
    "                features2[keys] = res\n",
    "\n",
    "        if operator == 'sum' :\n",
    "            features2={}\n",
    "            for keys in pairs:\n",
    "                test_dict1=newdict[keys[0]]\n",
    "                test_dict2=newdict[keys[1]]\n",
    "                #print(test_dict1)\n",
    "                #print(test_dict2)\n",
    "                res = {key: test_dict2[key] + test_dict1.get(key, 0) for key in test_dict2.keys()}  \n",
    "                features2[keys] = res\n",
    "\n",
    "\n",
    "        if operator == 'minus' :\n",
    "            features2={}\n",
    "            for keys in pairs:\n",
    "                test_dict1=newdict[keys[0]]\n",
    "                test_dict2=newdict[keys[1]]\n",
    "                #print(test_dict1)\n",
    "                #print(test_dict2)\n",
    "                res = {key: test_dict1[key] - test_dict2.get(key, 0) for key in test_dict2.keys()}\n",
    "                features2[keys] = res  \n",
    "\n",
    "\n",
    "        if operator == 'multiply' :\n",
    "            features2={}\n",
    "            for keys in pairs:\n",
    "                test_dict1=newdict[keys[0]]\n",
    "                test_dict2=newdict[keys[1]]\n",
    "                #print(test_dict1)\n",
    "                #print(test_dict2)\n",
    "                res = {key: test_dict2[key] * test_dict1.get(key, 0) for key in test_dict2.keys()}  \n",
    "                features2[keys] = res\n",
    "               \n",
    "\n",
    "           \n",
    "        dfObj = pd.DataFrame(features2)\n",
    "        dfObj=dfObj.transpose()\n",
    "        dfs.append(dfObj)\n",
    "\n",
    "       \n",
    "   \n",
    "\n",
    "       \n",
    "    return(pd.concat(dfs))\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "def preprocessing_features_single(input_feature,operator,given_pairs):\n",
    "    \n",
    "    newdict=input_feature.to_dict(orient=\"index\")   \n",
    "    dfs=[]\n",
    "    for pairs in [given_pairs]:\n",
    "       \n",
    "             \n",
    "               \n",
    "\n",
    "        if operator == 'minus' :\n",
    "            features2={}\n",
    "            for keys in pairs:\n",
    "                test_dict1=newdict[keys[0]]\n",
    "                test_dict2=newdict[keys[1]]\n",
    "                #print(test_dict1)\n",
    "                #print(test_dict2)\n",
    "                res = {key: test_dict1[key] - test_dict2.get(key, 0) for key in test_dict2.keys()}  \n",
    "                features2[keys] = res  \n",
    "               \n",
    "        if operator == 'abs_minus' :\n",
    "            features2={}\n",
    "            for keys in pairs:\n",
    "                test_dict1=newdict[keys[0]]\n",
    "                test_dict2=newdict[keys[1]]\n",
    "                #print(test_dict1)\n",
    "                #print(test_dict2)\n",
    "                res = {key: abs(test_dict2[key] - test_dict1.get(key, 0)) for key in test_dict2.keys()}  \n",
    "                features2[keys] = res\n",
    "               \n",
    "        if operator == 'multiply' :\n",
    "            features2={}\n",
    "            for keys in pairs:\n",
    "                test_dict1=newdict[keys[0]]\n",
    "                test_dict2=newdict[keys[1]]\n",
    "                #print(test_dict1)\n",
    "                #print(test_dict2)\n",
    "                res = {key: test_dict2[key] * test_dict1.get(key, 0) for key in test_dict2.keys()}  \n",
    "                features2[keys] = res\n",
    " \n",
    "       \n",
    "           \n",
    "        dfObj = pd.DataFrame(features2)\n",
    "        dfObj=dfObj.transpose()\n",
    "        dfs.append(dfObj)\n",
    "\n",
    "       \n",
    "   \n",
    "\n",
    "       \n",
    "    return(pd.concat(dfs))\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# make wee scoring function\n",
    "def ScoreMe(model, y_test, preds):\n",
    "    print(\"{}: accuracy report\".format(model))\n",
    "    print(\"The accuracy is {}\".format(accuracy_score(y_test,preds)))\n",
    "    print(\"The recall is {}\".format(recall_score(y_test, preds)))\n",
    "    print(\"The precision is {}\".format(precision_score(y_test, preds)))\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    print(\"specificity is {}\".format(specificity))\n",
    "    print(\"The  F1 score  is {}\".format(f1_score(y_test, preds)))\n",
    "    return()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# make wee scoring function\n",
    "def ScoreMe_2(model, y_test, preds):\n",
    "    acc=accuracy_score(y_test,preds)\n",
    "    recall=recall_score(y_test, preds)\n",
    "    prec=precision_score(y_test, preds)\n",
    "    f1=f1_score(y_test, preds)\n",
    "    return([acc,recall,prec,f1])\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files_toRead=[\"./features/protR_IDRs_concenated_15.txt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation - Fold: 1 \n",
      "ROC AUC : 0.7356\n",
      "Cross-validation - Fold: 2 \n",
      "ROC AUC : 0.6807\n",
      "Cross-validation - Fold: 3 \n",
      "ROC AUC : 0.6878\n",
      "Cross-validation - Fold: 4 \n",
      "ROC AUC : 0.7589\n",
      "Cross-validation - Fold: 5 \n",
      "ROC AUC : 0.6625\n",
      "Cross-validation - Fold: 6 \n",
      "ROC AUC : 0.7890\n",
      "Cross-validation - Fold: 7 \n",
      "ROC AUC : 0.6835\n",
      "Cross-validation - Fold: 8 \n",
      "ROC AUC : 0.7095\n",
      "Cross-validation - Fold: 9 \n",
      "ROC AUC : 0.6543\n",
      "Cross-validation - Fold: 10 \n",
      "ROC AUC : 0.6898\n"
     ]
    }
   ],
   "source": [
    "for q in range(1,11):\n",
    "    for r in range(1):\n",
    "        \n",
    "        print(\"Cross-validation - Fold: {} \".format(q))\n",
    "\n",
    "       \n",
    "        filetoRead=files_toRead[r]\n",
    "\n",
    "\n",
    "\n",
    "        output=create_pairs_order_uniq(iteration=q,seed=30)\n",
    "        positive_pairs=output[0]\n",
    "        negative_pairs=output[1]\n",
    "        all_pairs=output[2]\n",
    "           \n",
    "        df_ProtR =pd.read_csv(filetoRead,sep=\"\\t\",header=0,index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        result=preprocessing_features_orig(df_ProtR,'minus',positive_pairs,negative_pairs)\n",
    "\n",
    "                               \n",
    "                   \n",
    "        listOfStrings1 = [1  for i in range(len(positive_pairs))]\n",
    "        listOfStrings2 = [0  for i in range(len(negative_pairs))] \n",
    "        result['interaction']= listOfStrings1+listOfStrings2\n",
    "\n",
    "        balanced_index=copy.deepcopy(all_pairs)\n",
    "\n",
    "           \n",
    "        trainingpositive_df=result.loc[balanced_index[0] , : ]\n",
    "        trainingnegative_df= result.loc[balanced_index[2] , : ]\n",
    "\n",
    "        testpositive_df=result.loc[ balanced_index[1] , : ]\n",
    "        testnegative_df=result.loc[ balanced_index[3] , : ]\n",
    "\n",
    "\n",
    "        \n",
    "        training_subsetted=[trainingpositive_df,trainingnegative_df]\n",
    "\n",
    "        df = pd.concat(training_subsetted)\n",
    "        y_train = df.interaction\n",
    "        X_train = df.drop(['interaction'], axis=1)\n",
    "        \n",
    "\n",
    "        test_subsetted=[testpositive_df,testnegative_df]\n",
    "        df_result_test = pd.concat(test_subsetted)\n",
    "\n",
    "        y_test = df_result_test.interaction\n",
    "        X_test = df_result_test.drop('interaction', axis=1)\n",
    "               \n",
    "\n",
    "\n",
    "        rfminus = RandomForestClassifier(random_state=42,n_jobs=-1,min_samples_split=0.1,max_depth=5)\n",
    "        rfminus.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "        ###\n",
    "\n",
    "        ## import test pairs that are already sorted based on the known node\n",
    "        \n",
    "        filename_1= \"./asymmetric_pairs/ordered_testpairs/test_file_ordered_x_\"+str(q)+\".pkl\"\n",
    "        filename_2= \"./asymmetric_pairs/ordered_testpairs/test_file_ordered_y_\"+str(q)+\".pkl\"\n",
    "        \n",
    "        \n",
    "    \n",
    "        with open(filename_1, 'rb') as f:\n",
    "            testpairs_pickle = pickle.load(f)\n",
    "\n",
    "        with open(filename_2, 'rb') as f:\n",
    "            labels_pickle = pickle.load(f)\n",
    "        \n",
    "    \n",
    "\n",
    "        X_test_updated=preprocessing_features_single(df_ProtR,'minus',testpairs_pickle)\n",
    "        X_test_updated=X_test_updated[X_train.columns]\n",
    "        \n",
    "        \n",
    "        \n",
    "        preds = rfminus.predict(X_test_updated)\n",
    "        probs= rfminus.predict_proba(X_test_updated)\n",
    "        \n",
    "    \n",
    "        score = roc_auc_score(labels_pickle, probs[:, 1])\n",
    "        print(f\"ROC AUC : {score:.4f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a6292a977ae281f17d6ee727df354fd0d3024cab88f5502d0a3b63d3f3caca"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
